---
permalink: /
title: "Bio"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Reinforcement Learning enables agents to learn optimal behavior through interactions with an environment; it helps humans and animals rapidly adapt to new circumstances, and drives the emergence of complex learned behaviors. My research is focused on **Reinforcement Learning**—developing **scalable and resilient algorithms** that enable reliable decision-making in complex, single-situated, multi-agent, and distributed environments to see complex, human-like behavior emerge from unsupervised interaction with an application’s focus on game theory, and techniques for decision-making (planning and learning) that exhibit goal-directed behavior. I draw upon techniques from **optimization, machine and deep learning, and statistics** to tackle challenges at the intersection of theoretical foundations and practical deployment of RL. Concretely, this leads to a lot of questions I’m currently interested in:
How can interaction lead to better behavior, better perception, better models of the world? 
How can we develop RL algorithms that can generalize to new situations and adapt to changing environments? <br>


My work addresses several key areas: <br>
 
- **RL for/via generative models:** I investigate RL integration with generative models to improve their performance, particularly in tasks where traditional training objectives like maximum likelihood estimation fall short in order to provide a framework for optimizing generative models based on complex, non-differentiable, or preference-driven objectives.
- **Core RL theory:** I aspire to work on building the theoretical foundation of reinforcement learning (RL), especially in the function-approximation setting.
RL with offline and online data: Studying sample-efficient reinforcement learning, and developing algorithms and theories for learning near-optimal policies.
- **Representation and meta learning in RL:** I study scalable frameworks for submodular maximization and adaptive meta-learning for discrete tasks, focusing on applications that demand large-scale processing and resilience to data uncertainty. I am also interested in the theory of representation learning and representation transfer in RL.
- **Algorithmic and theoretical foundations of RLHF:** Exploring analogies between large language models and reinforcement learning.<br>


I am an Independent Researcher, currently applying for a PhD in Computer Science in the US. Previously, I worked as a Research Assistant under the guidance of Dr. Essa Alghannam, where I focused on time series and computer vision research. I completed my BSc degree in Mechatronics Engineering at Tishreen University in 2022, where Doctor Iyad Hatem was my supervisor. I, additionally, collaborated and worked closely with Doctor Tammam Haidar on Bayesian machine learning. 

